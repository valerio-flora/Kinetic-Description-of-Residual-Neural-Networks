This project explores the connection between neural networks and partial differential equations (PDEs), focusing on the development of kinetic neural differential equations. 
These equations model neural networks as dynamic systems of interacting particles, extending traditional mean-field equations to capture individual behaviors. 
The thesis investigates the application of these models to regression, classification, and distribution fitting tasks, with theoretical guarantees on solution convergence. 
Special attention is given to noisy settings, where Boltzmann and Fokker-Planck formulations provide deeper insights into network dynamics. 
Numerical simulations in MATLAB support the theoretical findings, showcasing enhanced performance in high-dimensional contexts compared to mean-field approaches. 
This work bridges neural networks and PDEs, offering novel perspectives for both theoretical research and practical algorithms.
